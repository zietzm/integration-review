## Discussion

Machine learning techniques have broadly been classified into two disjoint categories, supervised and unsupervised [^1].
While in reality the two categories represent endpoints of a continuum, this review will consider the only the binary discretum.
Through such a lens, "supervised" refers to techniques which attempt to learn mappings between specified inputs and outputs.
A simple example of a supervised learning technique is logistic regression, which attempts to assign binary labels to data points after being trained on labeled data.
"Unsupervised" learning refers to techniques which identify characteristics of data without labels.
A simple example of unsupervised learning is principal component analysis (PCA), which transforms observations onto a new set of coordinates that represent the axes of greatest variance.
The discussion that follows is split between supervised and unsupervised methods.
At present, greater advances appear to have been made in unsupervised methods, though supervised methods can be strengthened and enabled by first applying unsupervised data integration, feature selection, or de-noising.

[^1]: An oft-included third category is reinforcement learning, in which a computational agent learns actions to maximize a reward function. While such methods show promise for biological applications like the prediction of protein folding, they are beyond the scope of this review.

### Unsupervised methods

A very useful application of unsupervised methods is the transformation of large noisy data into a useful, de-noised format which can used for supervised machine learning.
For example, Greene et al. [@doi:10.1038/ng.3259] constructed tissue-specific functional gene networks using data from over 14,000 experiments.
By integrating tissue-specific expression information in a Bayesian framework, the authors constructed networks of tissue-specific gene functional relationships, with edge weights representing the posterior probability of a functional relationship.
These edges weights were determined by a naive Bayes classifier that was trained to predict positive functional relationships based on tissue-specific data.
A key insight by the authors was that tissue-specific networks represent as data-driven method for the analysis of noisy GWAS data.
The corresponding method is outlined later in this review.

Another data-integrative application of functional networks was proposed by Sehgal et al. [@doi:10.1371/journal.pone.0140072], who developed a methodology called the Robust Selection Algorithm (RSA) to identify micro-RNAs (miRNA) which are oncogenic or tumor-suppressing.
By incorporating functional networks of miRNA-mRNA data, the authors were able to account for non-linear relationships between molecular markers and patient outcomes.
Using data from TCGA, RSA was able to identify a number of both onco-miRNA and tumor-suppressor miRNA with relevance for the prediction of survival times in various cancers.
To generate functional networks, the authors employed the NetWalker [@doi:10.1186/1471-2164-13-282] suite of software, a self-described, "one-stop platform," for network-based data methods for integrative genomics.

A common goal of network-based systems biology is the identification of functionally-related modules (or sub-networks) within larger networks of genes or proteins.
Ideker et al. [@doi:10.1093/bioinformatics/18.suppl_1.S233] developed an approach to integrate protein-protein and protein-DNA interactions with mRNA expression data to identify "active" subnetworks.
Defined as, "connected sets of genes with unexpectedly high levels of differential expression," active subnetworks were identified by finding groups of nodes with significant differential expression, the _collective_ expression of which was compared to randomly chosen subnetworks.
Having scored subnetworks, the authors' method then finds the highest-scoring subnetworks using simulated annealing.
Subsequent research in module network inference has expanded the methods' capabilities to most common types of omic data.
Lemon-Tree, due to Bonnet et al. [@doi:10.1371/journal.pcbi.1003983], is an open-source software package that encompasses many validated algorithms and novel approaches for module network inference.

iCluster [@doi:10.1093/bioinformatics/btp543] is a joint latent variable model, which attempts to estimate unobserved tumor subtypes using available multiomic data such as CNV, DNA methylation, and mRNA expression.
The method estimates tumor subtypes by maximizing a set of linear equations using maximum likelihood and the expectation-maximization algorithm.
Applying the method to breast cancer, the authors were able to identify four disease subtypes, recovering well-known clinical subtypes, as well as identifying potentially novel subtypes of the disease.

Network-based methods for biomedical data integration are not limited to representations in which nodes represent genes, proteins, RNA molecules, or other molecular entities.
Similarity Network Fusion (SNF), a method due to Wang, et al. [@doi:10.1038/nmeth.2810], uses patient similarity networks to cluster patients into discrete and clinically-meaningful groups.
In these networks, nodes represent patients and the edges connecting patients represent their pairwise similarity.
For each additional data modality, SNF creates a similarity network based on the patients' molecular profiles.
The constructed modality-specific networks are then fused using an iterative linear algebra routine which is appropriate for studies of varied sample size and feature number, as well as for highly heterogeneous data sources.
The authors applied SNF to three data modalities for a case study of glioblastoma multiforme (GBM), an aggressive brain tumor which is challenging to treat [@raw:aans].
Previous data-integrative approaches had shown varied results, including the identification of a variable numbers of disease subtypes, depending on the data modality under investigation.
Using SNF, the authors were able to recover known clinically-relevant disease subtypes and show that these subtypes correspond to very different survival prognoses.
Moreover, by probing the network resulting from the SNF method, the authors were able to show that the majority of the edges were supported by two or more different data modalities, strengthening confidence in the validity of their integrative method.

Applying individual weights to networks is a natural next-step for the fusion of multiomic networks.
In a separate application of SNF, Angione et al. [@doi:10.1186/s12859-016-0912-1] developed a network approach for bacterial growth and response, in which nodes represent growth conditions and edges represent the similarities between conditions.
In a modification to the original SNF method, Angione et al. propose a weighted or "biased" SNF method in which layers themselves can be weighted according to the predictive quality of the various data.
The authors state that this modification also increases the method's robustness to distributions with high kurtosis.
After consolidating the network into a single, global representation of the multi-modal data, the authors were able to predict _E. coli_ metabolism under a range of possible growth conditions.

Mosca et al. [@doi:10.1039/C3MB70327D] developed a multi-objective data fusion method, in which both component- and network-level estimators are optimized.
As in the biased SNF method, networks themselves are weighted during the integration procedure.
Unlike the previous work, though, the multi-objective method finds optimal weights for both networks and nodes, thus leaving fewer hyperparameters needing user-given specification.
A difficulty of the MO method lies in the definition of objective functions to be minimized.
While the authors propose several (over-representation analysis statistics, functional class scoring Ã  la GSEA, etc.), it is not clear which metric would be most appropriate for any given situation.
Nonetheless, the method presented is an interesting and novel way to optimize the multiomic sets of networks that arise in integrative genomics.

Another key application for unsupervised data integration methods is the prioritization or ranking of the molecular causes of disease.
Greene et al. [@doi:10.1038/ng.3259] developed a method called NetWAS to re-prioritize genes with nominally-significant p-values from standard GWAS methods.
NetWAS uses tissue-specific functional networks as features when training a support vector machine (SVM) classifier to predict whether a gene was nominally significant in a GWAS study.
After training, genes can be re-ranked according to their distance from the SVM decision hyperplane.
The rationale behind this method is that the SVM is able to capture some characteristics of the data which lead to significant gene enrichment, while genes with spurious p-values will not share the same functional characteristics.
One of the pivotal innovations of NetWAS is the ability to re-prioritize or cross-prioritize genes from distinct GWAS studies in a method that does not depend on _a priori_ knowledge of the disease.

Aerts et al. [@doi:10.1038/nbt1203] also developed a method to prioritize the genes that potentially underlie disease.
Named Endeavor, the method ranks genes based on their similarity to genes known to be involved in the disease.
After producing a ranking using each data modality available separately, the ranking lists are combined.
In a later paper, De Bie et al. [@doi:10.1093/bioinformatics/btm187] improved upon the Endeavor methodology by devising a kernel-based method to rank genes within a single data modality.
Both of these methods have the disadvantage of needing comparison data in which to contextualize unseen observations.

Overall, unsupervised data integration methods have made tremendous progress in the past two decades.
These methods have shown promise for the generation of useful datasets, the data-driven identification of disease subtypes and patient clusters, as well as for the extraction of information pertinent to prediction tasks.

### Supervised methods

While supervised learning methods are methodologically quite distinct from unsupervised approaches, the underlying learning is fundamentally similar.
In both cases, the goal is to develop computational models that are able to learn about the intrinsic qualities, connections, and variation patterns within high-dimensional, noisy data.
Supervised learning then leverages this lower-level understanding to make explicit and testable predictions about observed data.

A classic application of supervised learning to networks is the task of edge prediction.
Within networks of a single type, several common methods exist.
A basic approach involves dropping several nodes from the network, computing walk-counts between pairs of nodes, then using these counts as features to predict the edges which were dropped.
Superior methods have been devised, but few are immediately applicable to multi-modality datasets in a way that would produce meaningful and interpretable results.
Another key application of supervised learning is the prediction of node sets that are related in some way or relevant to some other phenomenon.
Among the most common applications is the prediction of genes that are relevant to a particular disease.

Himmelstein et al. [@doi:10.1371/journal.pcbi.1004259] created a so-called "heterogeneous" network with nodes representing biomedical entities of many different types.
Fundamentally, the authors' data integration strategy is simply the joining of multiple types of relationship data (eg: genes, diseases, molecular functions, compounds) along sets of common vocabularies.
After creating a multipartite network with over 40,000 nodes and 1,600,000 edges, the authors performed a number of prediction tasks, illustrating the power of integrative approaches.
As features to their predictive models, the authors devised a novel metric of node pair interconnected-ness, termed the "degree-weighted path count," (DWPC).
Computed by traversing the network across multiple semantic types of paths (eg: Gene-Associates-Disease-treated by-Compound), DWPC allowed the authors to predict withheld high-confidence associations from the GWAS catalog at an area under the receiver operating curve (AUROC) of 0.83.

In a follow-up application [@doi:10.7554/eLife.26726] the authors utilized a similar method to predict candidates for drug repurposing within a much-enlarged network.
Predicting treatments for epilepsy, the authors were able to recapture (withheld) 23 of 25 known anti-epileptic drugs.
One of the advantages of the heterogeneous network method is that connections between any two types of biological entities in the network can be predicted using the same methodology.
A drawback of this method is that gold-standard data must be obtained for the connection-type to be predicted, which could be challenging for certain types of biological connections.

Hypothesizing that many genes involved in cancer development may not be identified by conventional methods such as differential expression or mutation analysis, Ruffalo et al. [@doi:10.1371/journal.pcbi.1004595] devised a method to identify these so-called, "Silent players."
Fundamentally, the method seeks to identify proteins involved in cancer by computing the proximity of all human proteins to products of genes which are differentially-expressed or mutated.
"Proximity" in this context is computed by network propagation and results in two vectors (one for each of the input data modalities).
These features are then used to predict the probability of the gene being involved in the disease of interest.
While the method described in the paper integrates only mutation and differential expression data with protein-protein interaction networks, the method could, in principle, be applied to similar data modalities as well, provided suitable networks exist for the modalities of interest.

Supervised methods also lend themselves to the prediction of clinical outcomes.
Kim et al. [@doi:10.1016/j.jbi.2012.07.008] used multiomic data to predict outcomes for several cancers.
Their data integration method first created a patient similarity network for each data modality.
Next, the individual networks were merged by finding the optimal coefficients for a linear combination of graphs such that an objective function involving the graph Laplacian was minimized [^2].
This work preceded the publication of SNF, though it is similar in approach and in effect.
After merging modality-specific networks into a global network of patient similarities, the authors predicted clinical outcomes using a nearest-neighbor approach.

Shin et al. [@doi:10.1093/bioinformatics/btm511] created an integrated network of proteins by finding the optimal linear combination of individual graph Laplacians.
Importantly, they developed a method called graph sharpening, in which edges between labeled and unlabeled points are removed from the graph.
Sharpening reduces the noise found in a graph by eliminating undesired edges.
The authors found that this method, when applied in conjunction with network integration, affords the greatest improvement for the task of predicting whether proteins are members of a gene ontology (GO) category.

Other clinical events beyond the emergence of disease can be predicted as well.
Mankoo et al. [@doi:10.1371/journal.pone.0024709] developed a model with a focus on reducing the number of features used for prediction and increasing the biological interpretablility of outcomes.
In the study, the authors sought to predict clinical outcomes for patients with serous ovarian cancer using multiomic data from TCGA.
Their method filtered features by computing the Spearman rank correlations between data types and removing all features below chosen cut-offs.
Overall, this procedure reduced the number of features from roughly 50,000 to under 200.
Using the reduced feature set, the authors predicted discrete outcomes and continuous time to recurrence better than with any of the data types alone.

[^2]: Note, the Laplacian for a graph is defined as the diagonal degree matrix (elements on the main diagonal correspond to the degree of the respective node) minus the adjacency matrix.
